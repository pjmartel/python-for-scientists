{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "linear_regression_with_intervals",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pjmartel/python-for-scientists/blob/master/linear_regression_with_intervals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7REiKuRCu0T9",
        "colab_type": "text"
      },
      "source": [
        "#### Introduction to Simple Linear Regression\n",
        "\n",
        "Linear regression is a common task in data analysis and modelling. Let's consider we have  data for a dependent variable $x_i$ and an independent variable $y_i$, and we have reason to believe they are connected by a simple linear relation:\n",
        "\n",
        "$$y_i = m x_i + b ,$$\n",
        "\n",
        "where $m$ and $b$ are paramenters whose \"true\" value is unknown. In that case, we can try to find estimates $\\hat m$ and $\\hat b$ such that the difference\n",
        "\n",
        "$$ y_i - \\hat y_i $$ \n",
        "\n",
        "\n",
        "is minimized, where  \n",
        "\n",
        "$$ \\hat{y_i} = \\hat m x_i + \\hat b$$\n",
        "\n",
        "For mathemical reasons it is more convenient to minimize the *Sum of Squares*, given by:\n",
        "\n",
        "$$ SS(\\hat m, \\hat b) = \\sum_i (y_i - \\hat y_i )^2 $$\n",
        "\n",
        "\n",
        "Minimzing the $SS(\\hat m, \\hat b) $ as function of m and b gives rise to the well know formulas:\n",
        "\n",
        "$${\\displaystyle {\\begin{aligned}{\\widehat {b }}&={\\bar {y}}-{\\hat {m}}\\,{\\bar {x}},\\\\[5pt]{\\hat {m }}&={\\frac {\\sum _{i=1}^{n}(x_{i}-{\\bar {x}})(y_{i}-{\\bar {y}})}{\\sum _{i=1}^{n}(x_{i}-{\\bar {x}})^{2}}}\\\\[6pt]&={\\frac {\\operatorname {Cov} (x,y)}{\\operatorname {Var} (x)}}\\\\[5pt]&=r_{xy}{\\frac {s_{y}}{s_{x}}}.\\\\[6pt]\\end{aligned}}}  $$\n",
        "\n",
        "There are multiple implementations of this method in the Pyverse, some specific to this model, some much more general. The Numpy module has a function named \"`polyfit`\" that can do least squares regression for a polynomial function:\n",
        "\n",
        "$$ y = a_n x^n + a_{n-1} x^{n-1} + ... + a_1 x + a_0$$\n",
        "\n",
        "Our simple linear model is just a particular case of the above, for $n=1$.\n",
        "\n",
        "Let demonstrate the use of this function with a simulated linear dataset model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mthr025pooTW",
        "colab_type": "text"
      },
      "source": [
        "#### Testing Linear Regression with Simulated Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wm3PqCPW2pEe",
        "colab_type": "text"
      },
      "source": [
        "First, we do the necessary imports:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4fLHx5Et72A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "#from matplotlib import style\n",
        "#style.use('dark_background')\n",
        "import numpy.random as rnd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TdO-1X-216T",
        "colab_type": "text"
      },
      "source": [
        "We import the *random* module of numpy because we want to add random noise to our simulated data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXNE27zs2-da",
        "colab_type": "text"
      },
      "source": [
        "Let's create a numpy 1D array for our independent variable;"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NobE_PeZuInB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N = 20 # number of data points\n",
        "x = np.linspace(0,10, N)\n",
        "x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2hUO8Jx3PfU",
        "colab_type": "text"
      },
      "source": [
        "Let's create our independent variable `y`  by aplying the linear model to independent variable:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKNMfwbR3JMo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m = 3\n",
        "b = 2\n",
        "y = m*x + b "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZMwqTCD3bXg",
        "colab_type": "text"
      },
      "source": [
        "Let's plot the y *versus* x "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhqGbQaw3aHr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(x,y,'ro--')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkbbuYGX39cH",
        "colab_type": "text"
      },
      "source": [
        "This is not that interesting, because our independent variable has no error, so the fitting to the linear model is perfect.\n",
        "\n",
        "Let's add some random gaussian noise to our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEalt3Zq39Id",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Normal distribution with mean 0 and std 1, N points\n",
        "y = y + rnd.normal(loc=0, scale=1, size=N) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0e7P009-l-8",
        "colab_type": "text"
      },
      "source": [
        "We just added a normally distributed random number (mean=0, std=1) to every point in our sample. This *simulates* experimental errors in the measurment of variable $y$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrBK2-Ws37iW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(x,y,'yo')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdW_FfEH4hGF",
        "colab_type": "text"
      },
      "source": [
        "That's more like it! We can now use the `polyfit` function to estimate the linear parameters of our \"hidden\" model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daoiAuG23k5t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.polyfit(x,y,deg=1) # simple linear mode = polynomial degree one "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySzdVEAO0ChS",
        "colab_type": "text"
      },
      "source": [
        "We can see that our function returns the two estimates of m and b as two elemens of a numpy array. In cases like this, it is convenient \n",
        "assign the return values directly to two separate variables:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMGx4n4K4vkf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mhat, bhat = np.polyfit(x,y,deg=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38PpEw4N0ehq",
        "colab_type": "text"
      },
      "source": [
        "We use the \"hat\" designations to emphasize the fact that m and b are not the \"true values\" (unknown in real-life scenarios, but known \n",
        "here for simulated data ), but rather *estimates* of the true variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJd9lnyaz2mc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"mhat ={:6.3f}  bhat ={:6.3f}\".format(mhat,bhat))\n",
        "print(\"m ={:6.3f}  b ={:6.3f}\".format(m,b))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Q6xxAkh17oj",
        "colab_type": "text"
      },
      "source": [
        "As you can see, there is considerable discrepancy between the estimated and the \"true\" values, particularly for the the b parameter.\n",
        "\n",
        "**HANDS-ON:** Compute the *Pearson correlation coefficient* ($r_{xy}$), and its square, the *Coefficient of determination*($R^2$)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbhuLipy2Ici",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title SOLUTION \n",
        "print(\"Pearson correlation coefficient - \",np.corrcoef(x,y)[1,0])\n",
        "print(\"Coefficient of determination (R²) - \",np.corrcoef(x,y)[1,0]**2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZj6FVMx330l",
        "colab_type": "text"
      },
      "source": [
        "Let's plot the regression line together with our data point, with proper labels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Va0MZKkl33yS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.title(\"Simple linear regression\")\n",
        "plt.xlabel(\"x data\")\n",
        "plt.ylabel(\"y data\")\n",
        "plt.plot(x,y,'yo',label=\"data points\")\n",
        "plt.plot(x,mhat*x+bhat,'g--', label=\"regression line\")\n",
        "plt.legend();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrNgW5RI8Tyh",
        "colab_type": "text"
      },
      "source": [
        "**HANDS-ON:** Go and try to re-run the above cells several times. Each time the random error will be different, so you will get different values for mhat, bhat and R². This will give you a good feeling for the *interval* of variation that our estimates can populate when data is sampled from a population with a given error distribution (in this case the random error is normall distributed with mean 0 and standard deviation 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQuAv5dxovwB",
        "colab_type": "text"
      },
      "source": [
        "#### Confidence Intervals for Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ua7sL4jx_RLT",
        "colab_type": "text"
      },
      "source": [
        "The intervals of variation of $\\hat m$ and $\\hat b$  should gives a measure of the *confidence* we can have in our estimates. A more rigorous way to deal with the problem would be to obtain *confidence intervals* for $\\hat m$ and $\\hat b$. Unfortunately, most tools to compute simple linear regression do not produce this values, which can be crucial if parameter estimation is our primary goal.  It's even more suprising considering that implementation of the computations for the said intervals is actually rather simple. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8v5y2WDAvPU",
        "colab_type": "text"
      },
      "source": [
        "**HANDS-ON:** Implement the necessary calculations for computing the intervals for $\\hat m$ and $\\hat b$ at a given confidence level, based on the explanation given below:\n",
        "\n",
        "If the random errors in the $y$ variable are normally distributed, the $\\hat m$ and $\\hat b$ values are themselves normally distributed, and a confidence interval for the \"true\" value $m$ and $b$ can be determined. We will assert without demonstration that :\n",
        "\n",
        "<br>\n",
        "$${\\displaystyle {\\frac {{\\hat {m }}-m }{s_{\\hat {m }}}}\\ }$$\n",
        "<br>\n",
        "\n",
        "is distributed with a Student's t-distribution with $t-2$  degrees of freedom (henceforth called $t_{n-2}$), where $s_{\\hat m}$ is given by:\n",
        "\n",
        "<br>\n",
        "$$ s_{\\hat {m }}={\\sqrt {\\frac {{\\frac {1}{n-2}}\\sum _{i=1}^{n}{\\hat {\\varepsilon }}_{i}^{\\,2}}{\\sum _{i=1}^{n}(x_{i}-{\\bar {x}})^{2}}}}$$\n",
        "<br>\n",
        "\n",
        "where the $\\varepsilon_i$ are the differences between the experimental and calculated $y$:\n",
        "\n",
        "<br>\n",
        "$$\\varepsilon_i = \\hat y_i - y_i = \\hat m x_i+ \\hat b - y_i $$\n",
        "<br>\n",
        "\n",
        "and the $\\bar x$ is the sample mean of the $x$ values:\n",
        "\n",
        "<br>\n",
        "$$ \\bar x = \\frac{1}{N}\\sum_i x_i $$\n",
        "<br>\n",
        "\n",
        "From here a confidence interval can be found for $m$ :\n",
        "\n",
        "<br>\n",
        "$${\\displaystyle m \\in \\left[{\\hat {m }}-s_{\\hat {m }}t_{n-2}^{*},\\ {\\hat {m }}+s_{\\hat {m }}t_{n-2}^{*}\\right]}$$\n",
        "<br>\n",
        "\n",
        "where ${\\displaystyle t_{n-2}^{*}}$ is the ${\\displaystyle \\scriptstyle \\left(1\\;-\\;{\\frac {\\gamma }{2}}\\right){\\text{-th}}}$ quantile of the Student's t distribution with n−2 degrees of freedom. For example, if γ = 0.05 then the confidence level is 95%\n",
        "\n",
        "Similarly, a confidence interval for $ b$ is \n",
        "\n",
        "<br>\n",
        "$${\\displaystyle b \\in \\left[{\\hat {b }}-s_{\\hat {b }}t_{n-2}^{*},\\ {\\hat {b }}+s_{\\hat {b }}t_{n-2}^{*}\\right]}$$\n",
        "<br>\n",
        "\n",
        "where $s_{\\hat b}$ is the standard error of the $b$ estimate:\n",
        "\n",
        "<br>\n",
        "$${\\displaystyle s_{\\hat {b }}=s_{\\hat {m }}{\\sqrt {{\\frac {1}{n}}\\sum _{i=1}^{n}x_{i}^{2}}}}$$\n",
        "<br>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4juD_6KMbkF",
        "colab_type": "text"
      },
      "source": [
        "**NOTE 1:** The ${\\displaystyle \\scriptstyle \\left(1\\;-\\;{\\frac {\\gamma }{2}}\\right){\\text{-th}}}$ quantile of the Student's t distribution with n−2 degrees of freedom can be calculated using the \"stats\" module of the \"scipy\" scientific library. Here is what to do:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0k-rBNf1U_B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.stats import t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAzrze83NYQN",
        "colab_type": "text"
      },
      "source": [
        "The t module contains many functions related to the  $t$ distribution, including probability density, cumulative distribution, and many others. The function\n",
        "we need to calculate the quantile is  \"`t.ppf`\" (percent point function). Let's calculate the correct t-value for a give percent confidence interval:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbg4C-nf9ViW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N = 20 # number of points\n",
        "interval = 0.95 # confidence interval\n",
        "gamma = 1-interval\n",
        "tval = t.ppf(1-gamma/2,df=N-2)\n",
        "tval"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNatOBIYPyQA",
        "colab_type": "text"
      },
      "source": [
        "**NOTE 2:** Remeber the exercises in the numpy notebook where we found numpy vector expressions to calculate variance/covariance and the correlation coefficient. We need to use a similar approach here. Calculations you need to do:\n",
        "\n",
        "\n",
        "\n",
        "*   Mean of the sum of squares of $x_i$\n",
        "*   Sum of quadratic deviatrion from the mean of $x_i$\n",
        "*  Sum of the squares of differences between $\\hat y_i$ and $y_i$\n",
        "* From the above compute the $s_\\hat m$ and the $s_\\hat b$\n",
        "* Compute the $t$ value has explained above. \n",
        "* Use the $s_\\hat m$, $s_\\hat b$ and $t$ value to compute the confidence intervals\n",
        "\n",
        "1. Try to keep everything nice and tidy, defining a few functions to make the calculations more clear.\n",
        "\n",
        "2. Try to reuse some of the functions you created in the numpy exercise.  \n",
        "\n",
        "3. Ask the tutors help if you get stuck\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "937_bTINPMUB",
        "colab_type": "code",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "64b5e4dc-a833-4f09-ed7c-daa48bbddd3c"
      },
      "source": [
        "#@title SOLUTION\n",
        "import numpy as np\n",
        "import numpy.random as rnd\n",
        "from scipy.stats import t\n",
        "def sdmean(a):\n",
        "    \"\"\"\n",
        "Computes the sum square devation from the mean.\n",
        "    \"\"\"\n",
        "    from numpy import var\n",
        "    return var(a,ddof=0)*len(a)\n",
        "\n",
        "def SSD(a,b):\n",
        "  \"\"\"\n",
        "Computes the sum of squares deviation between two data vectors.\n",
        "  \"\"\"\n",
        "  return ((a-b)**2).sum()\n",
        "\n",
        "\n",
        "N=20\n",
        "m=3\n",
        "b=2\n",
        "x = np.linspace(0,10,N)\n",
        "y = m*x + b\n",
        "y = y + rnd.normal(loc=0,scale=1,size=N)\n",
        "interval = 0.95 # confidence interval\n",
        "\n",
        "mhat, bhat = np.polyfit(x,y,deg=1)\n",
        "yhat = x*mhat + bhat\n",
        "resi = SSD(y,yhat)\n",
        "\n",
        "gamma = 1-interval\n",
        "SDM = sdmean(x)\n",
        "sem = np.sqrt(resi/(N-2)/SDM)\n",
        "seb = sem*np.sqrt((x**2).mean())\n",
        "tval = t.ppf(1-gamma/2,df=N-2)\n",
        "print(\"m estimate:\", mhat)\n",
        "print(\"b estimate:\", bhat)\n",
        "#print(np.sqrt(sigma**2/SDM))\n",
        "#print(np.sqrt( sigma**2 * (1/len(x)+x.mean()**2/SDM)))\n",
        "#print(mbhat)\n",
        "print(f\"{100*interval}% confidence interval for m: \".format(interval),\n",
        "      [mhat-sem*tval, mhat+sem*tval])\n",
        "print(f\"{100*interval}% confidence interval for b : \".format(interval),\n",
        "      [bhat-seb*tval, bhat+seb*tval])\n",
        "print(\"R**2: (cf. of determination)\",1-resi/sdmean(y))\n",
        "print(\"Pearson correlation:\",np.corrcoef(x,y)[0,1])\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "m estimate: 3.010128478992552\n",
            "b estimate: 2.1681386234681512\n",
            "95.0% confidence interval for m:  [2.8958916933717256, 3.124365264613379]\n",
            "95.0% confidence interval for b :  [1.4999703468051941, 2.8363069001311083]\n",
            "R**2: (cf. of determination) 0.9941608294253023\n",
            "Pearson correlation: 0.9970761402346877\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWU4fLjCCJ6i",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYZSHcqZpI1y",
        "colab_type": "text"
      },
      "source": [
        "#### Visualizing linear regression with the Seaborn plotting library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoR9QG6bp5ns",
        "colab_type": "text"
      },
      "source": [
        "The Seaborn plotting library offers many visualizations beyond what matplotlib can do. Two plotting methods are used for linear regressions:\n",
        "\n",
        "* regplot - regression line with confidence band\n",
        "* residpplot - linear regresion residue plot\n",
        "\n",
        "Note, however, that this functions are purely *visual* - no numeric data concerning paramenters or confidence intervals is returned."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nO5FFqEMryDo",
        "colab_type": "text"
      },
      "source": [
        "Let's import the two functions from seaborn:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEYhz-iApN-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from seaborn import regplot, residplot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpwDB4L3r3dg",
        "colab_type": "text"
      },
      "source": [
        "Regression plot:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrG99H4EpTAQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "regplot(x,y,);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvGnUCQKr65z",
        "colab_type": "text"
      },
      "source": [
        "Plot of residuals (differences  between the $\\hat y_i$ and the $y_i$ ):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWJYds90pXdC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "residplot(x,y);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFILZbWHppEQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}