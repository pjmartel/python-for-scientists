{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Introduction_to_pandas.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pjmartel/python-for-scientists/blob/master/Introduction_to_pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxnLKHGezWdA",
        "colab_type": "text"
      },
      "source": [
        "#### Introduction \n",
        "\n",
        "We have learned to make various operations on 2D tabular data in the form of numpy arrays. While those operations can be very powerful tools for extracting all sorts if interesting patterns from the data, there is some some level of awkwardness in the data object itself. For one thing, numpy arrays  are mostly meant to work\n",
        "with uniform data types, whereas tabular datasets often have heterogeneous types of data. Numpy allow for the creation of *structured arrays* to deal with these heterogeneous data types, but it's just not as simple and immediate as one would hope. Tabular data often contains str fields, categorical values, floats and integers all combined in one very large table with many rows and columns. Rows are very often labelled with headings, very much like tables in Excel worksheets. When analyzing data with these type of tools, it's very often convenient to add new columns to our tables, our delete unneeded ones. Again, this can be done with Numpy arrays, but it's not practical. We could go on with a number of other aspects of data analysis were numpy arrays come short. \n",
        "\n",
        "With the very widespread usage of the Python language among data scientists and analysts, it's all but too natural that this issue was addressed in the form of a multi-tooled Python library. This library is called \"Pandas\" and its constructed around a type of object called \"dataframe\" that addresses many of the issues raised\n",
        "by working with tabular data (and also time series data). **Note:** Those familiar with the R programming language will recognize the dataframe type, which resembles its R counterpart in many ways."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7cNMAy-xIP2",
        "colab_type": "text"
      },
      "source": [
        "#### Basics of working with Pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5ZF9xgq-dz2",
        "colab_type": "text"
      },
      "source": [
        "Let's import the pandas library (\"pd\" is the recommend short-hand alias)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdKhbgEMke8J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_02Vlmu-nyn",
        "colab_type": "text"
      },
      "source": [
        "Pandas dataframes can be created with the \"DataFrame\" method in a number of ways.\n",
        "\n",
        "For instance, they can be created from a dict object, where the keys are column labels and the corresponding  values are lists of data to be contained in each column:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27d9lwyqH2EL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df = pd.DataFrame({'Name': ['lion','tiger','wolf','beer','panda'],'Avg.weight':})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ecv-QBLc4yyN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame({ 'A': [2, 3, 4, 5, 6] , 'B': [4, 9, 16, 25, 36]})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6ClG5LX_RxS",
        "colab_type": "text"
      },
      "source": [
        "Let's evaluate the dataframe \"df\" in a cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWq6sLw74yv1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkPH-RsB_ggQ",
        "colab_type": "text"
      },
      "source": [
        "As previously explained , the keys in the dictionary have been used for *column labels*, and the lists of values  as column data. Notice a leftmost column starting at 0 and going up to 4  - this is the index column of the data frame and can be used to access and manipulate the data rows in different ways - when not specifically set, his column will consist of numbers ranging from zero to the `n-1`, where `n` is the number of rows.. It is important to understand that the index column and the labels row are not part of the data proper, they are just entry points to label and access the data in ways that are simpler and faster than what you could do with a 2D Numpy array.  Also, the python notebook knows how to \"pretty print\" the dataframe in a nice tabular way,  with data properly aligned - it's far more readable that the default numpy array representation. \n",
        "<br><br>\n",
        "Suppose we want to print out the values of column A. We can do this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdM9hrPaAlHS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['A']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBFDYCvxHaeF",
        "colab_type": "text"
      },
      "source": [
        "The column values get printed along with indices, and the column data type is indicated below (Remember: dataframes will often include columns of different data types)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncbG8NvLBexu",
        "colab_type": "text"
      },
      "source": [
        "Column referencs like the one above can be operated by methods similar to those numpy arrays:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnxJdm7VAlYf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['B'].mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlHOarBLBptz",
        "colab_type": "text"
      },
      "source": [
        "The  column labels work much in the same way as row indices in a numpy 2D array, with the added convenience of (possibly) illustrative names. However,  this comes at a price: you can no longer access elements directly with slice notation. Just try it and see what happens:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjcNbeMXX6yb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df[3,2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiZ8-MeRYTSJ",
        "colab_type": "text"
      },
      "source": [
        "We got a \"KeyError\", because direct indexing of dataframes is done by column labels.  If you need to refer to elements of the dataframe using numpy-like slice notation, you should  use the \"iloc\" method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TO7eJVV3ZcwE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.iloc[1:3,1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jf6p7fciCIrk",
        "colab_type": "text"
      },
      "source": [
        "It is very easy to add new columns of labelled data to a dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8d1JzCuAlf7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['C'] = [8,9,3,5,6]\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKvNzGn0CdTy",
        "colab_type": "text"
      },
      "source": [
        "Simple as that! This is now clearly beyond normal numpy array territory  (although it's possible to do something similar with numpy arrays, it's much more convoluted) \n",
        "\n",
        "As previously mentioned, dataframes are prepared to handle a mix of different data types. Let's add another column, this time with str data instead of numbers:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TAK3M7-AliU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['D']= ['aaa','b','ccc','dd','eeeee']\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydQngl1XVYG5",
        "colab_type": "text"
      },
      "source": [
        "The type structure of a dataframe may easily be checked by inspecting its \"dtypes\" attribute:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knj21kmYWfk-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSdGj8R5SQpZ",
        "colab_type": "text"
      },
      "source": [
        "Operations on dataframe rowns and columns can be done similarly to numpy, using methos like \"sum\" or \"average\" and the \"axis\" parameter to select rowise or columnwise operations. For instance;"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YZQDcxvD3Ls",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.sum(axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qp2vJxtSUmr3",
        "colab_type": "text"
      },
      "source": [
        "or df.sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JydUVY3oUxiS",
        "colab_type": "text"
      },
      "source": [
        "Notice that pandas simply ignores the str column when calculating the averages along rows. For rowise computation one can simply do:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKdQs2Y8UqWF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.sum()   # same as df.sum(axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rTZpKcNbaQJ",
        "colab_type": "text"
      },
      "source": [
        "(notice string sum rule being applied to column D)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TND9xrBb3mL",
        "colab_type": "text"
      },
      "source": [
        "Let's create a new column, called \"SumBC\", containing the sum of values in columns B and C:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOXRPgh8cChc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['SumBC'] = df.iloc[:,1:3].sum(axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmaF7EoKXgsA",
        "colab_type": "text"
      },
      "source": [
        "(Remenber: slice notation \"`[:,1:3]`\" means \"any row, columns 1 to 2\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDtNZpXUcaDm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeU_YHejdMA7",
        "colab_type": "text"
      },
      "source": [
        "Now lets assume we want to create a another column, \"SumAC\", containing the sum of columns \"A\" and \"C\". We can do this in a very readable manner using the \"loc\" indexer object:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYtUBUdFD3JL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['SumAC'] = df.loc[:,['A','C']].sum(axis=1)   # Why do we need to use the \":\" symbol ?\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZB4fQAtYReS",
        "colab_type": "text"
      },
      "source": [
        "While \"`iloc`\" selects values in the dataframe based on row and column position (pretty like slice notation in numpy arrays), the  \"`loc`\" object indexer  creates selection based on index and column *labels*. This selections can als support slice syntax, for instance:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSdduNaLVRyB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.loc[1:3,'B':'D']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3h84VooVlMd",
        "colab_type": "text"
      },
      "source": [
        "**HANDS-ON:** Can you spot one important difference between the way slicing works for position based and label based ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2J3TERzV47-",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title ANSWER\n",
        "# a position range slice [a:b] means from a to b-1, while a label range\n",
        "# slice [a:b] means from label(or index) a to label (or index) b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGv-q-QOfZib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yRJPkqzfcAQ",
        "colab_type": "text"
      },
      "source": [
        "Removing data from the dataframa is as easy as adding it. Let's say we don't need the \"D\" column anymore:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZO4h5ICD3G8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.drop(columns=['D'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVc5aqbdlJPv",
        "colab_type": "text"
      },
      "source": [
        "We can also list and compute values in a conditional manner, combining logical expressions with indexing. Can yoy guess what the below expression does ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7-RGFyakzpX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['CondSum'] = df.loc[df['C']>6,'A':'C'].sum(axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qHnO0KvXHru",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqTEN06NmSVS",
        "colab_type": "text"
      },
      "source": [
        "That's right, this sums columns A to C and places the results in column \"CondSum\", but ONLY if the value in column C is above 6. When that condition is not met, there's nothing to place in the corresponding position of the \"CondSum\" column, and a \"NaN\" (Not a Number) value is stored there. We can think of NaN as a kind\n",
        "of placeholder that pandas uses when there no data available to fill that position. NaN will pop up when reading partially filled tabular data from a file, for instance. The missing values will appear as NaN in the dataframe. \n",
        "\n",
        "You can use \"`loc`\" in a sligntly different way to create columns based on conditions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBJxTvTP8LBK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.loc[df['A'] % 2 == 0, 'IsEven'] = True\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7KYvLN59EIR",
        "colab_type": "text"
      },
      "source": [
        "Notice the NaN where nothing was stored because the condtion wasn't met. We could fix it with a second line:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lN8Y5i499OQh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.loc[df['A'] % 2 != 0, 'IsEven'] = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEotlkmk9YDU",
        "colab_type": "text"
      },
      "source": [
        "**HANDS-ON**: Actually, this a somewhat contrived example, we could have also done the same thing with just one line. Can you guess how ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QQCDtOx8-UO",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title SOLUTION\n",
        "df['IsEven2'] = df['A'] % 2 == 0\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-hDIP0eYkJc",
        "colab_type": "text"
      },
      "source": [
        "#### Importing and working with a data file\n",
        "\n",
        "\n",
        "Ok, so we went through some basic operations on tabular data stored as a panda dataframe. In real world scenarios, these tabular data often need to be read from an external site, like a file on a web server or a remote disk. Rather than manually creating a dataframe from a `dict` object like we just did, we will want to \n",
        "read dataframes from large files that may have thousands of lines and columns. Fortunately for us, pandas data frames can be created from files in many different formats, including (but not limited to):\n",
        "\n",
        "\n",
        "\n",
        "*   CSV (comma-separated value)\n",
        "*   Excel\n",
        "*  Json\n",
        "* HTML\n",
        "* SQL\n",
        "\n",
        "<br>\n",
        "To illustrate this functionality, we are going to read a file in .csv format into a dataframe. As the name implies, csv files contain multiple lines with data items separated by commas. They often (but not necessarily) include a header line to be used as column labels, and a leftmost row label column. Obviously, it is up\n",
        "to the user to decide how such lines should be read - some knowledge on the organization of the imported dataset is usually necessary for proper data preparation and analysis. \n",
        "\n",
        "The csv data we are going to read is at the following link: https://raw.githubusercontent.com/pjmartel/python-for-scientists/master/datasets/grades_dataset.csv\n",
        "\n",
        "You can browse it by mousing over the link, clicking the right button and selecting the option \"open in new window\". You will recognize these data as a slightly more embellished version of the course grades we used in our numpy introduction. (Student names sound familiar ?... ).\n",
        "\n",
        "Let's read these data into a pandas dataframe using the appropriately named `read_csv` function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vAYEd70gC79",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grades = pd.read_csv(\"https://raw.githubusercontent.com/pjmartel/python-for-scientists/master/datasets/grades_dataset.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCyWenPCgK0l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grades"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZl-69KrlLps",
        "colab_type": "text"
      },
      "source": [
        "**HANDS-ON:** You have a number of tasks to perform with this dataset:\n",
        "\n",
        "\n",
        "\n",
        "1.   You realize that the table is missing the grades of two of the students! The names are \"Tyrion\" and \"Bronn\" and their grades are respectively `[15.2,  16.7, 16.0]` and `[17.0,15.2,17.7]`. Please add the missing grades! (Hint: consider using the \"`loc`\" indexer)\n",
        "2.   Calculate the student grade average of the three tests and place the values on a column labeled \"Average\"\n",
        "3.   Calculate the grade average for each test and place the value on a bottom row labeled \"test_averages\"\n",
        "4.  Create a new column named \"Status\" containing \"Pass\" or \"Fail\" depending on the grade average being higher or lower than 9.5. (Hint: look at the conditional expression above)\n",
        "5. Some of the students who have an above 9.5 grade average will nevertheless fail because they a had a grade < 7 in at least one of the three tests. Write an \n",
        "expression to correct the \"Status\" column accordingly (Hint: conditionals are again your friends, what does \"`a or b or c`\" evaluate  to when at least one of a, b and c is `False` ?)\n",
        "6. Sort the data based on the column \"Name\" (Hint: search for sort methods for a data frame, using TAB completion or the \"`dir`\" command)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5baPEZdn1U52",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title SOLUTION 1.\n",
        "grades.loc[11] = ['Tyrion',15.2,16.7,16.0]\n",
        "grades.loc[12] = ['Bronn',17.0,15.2,17.7]\n",
        "grades\n",
        "# Note: you must an index value outside the range 0-11 or else will \n",
        "# overwrite data rows (tow rows cannot have the same index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYGd2UXjme0_",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title SOLUTION 2.\n",
        "grades['Average'] = grades.iloc[:,1:4].mean(axis=1)\n",
        "grades"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eR6xnHDR3kuL",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title SOLUTION 2. (alternative solution)\n",
        "grades['Average'] = grades.loc[:,'1st Test':'3rd Test'].mean(axis=1)\n",
        "grades"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYDFHS_umoWK",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title SOLUTION 3.\n",
        "grades.loc['test_averages'] = grades.iloc[:,1:5].mean(axis=0)\n",
        "grades"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9XP_JLTnSjZ",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title SOLUTION 4. \n",
        "grades.loc[grades.Average >= 9.5, 'Status'] = 'Pass'\n",
        "grades.loc[grades.Average < 9.5, 'Status'] = 'Fail'\n",
        "grades"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QP3G4OPw5nYV",
        "colab_type": "code",
        "colab": {},
        "cellView": "both"
      },
      "source": [
        "#@title SOLUTION 4. (alternate solution)\n",
        "import numpy as np\n",
        "grades['Status'] = np.where(grades['Average']>=9.5, 'Pass', 'Fail')\n",
        "grades\n",
        "# Can you understand how this works ?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GswBk6bbQG2x",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title SOLUTION 5.\n",
        "grades.loc[ (grades['1st Test']<7.0) | (grades['2nd Test']<7.0) | (grades['3rd Test']<7.0),'Status'] = 'Fail'\n",
        "grades"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PW0WJiK9TLzH",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title SOLUTION 6.\n",
        "grades = grades.sort_values('Name') \n",
        "# by default, sort_values is not an in place operation!\n",
        "grades"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWiqQp-0WMY5",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title SOLUTION 6. (alternative solution)\n",
        "grades.sort_values('Name',inplace = True)\n",
        "grades"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdCQONCAW9Bk",
        "colab_type": "text"
      },
      "source": [
        "Ok, if you solved the Hands-On properly, you should be left with the data frame in this state:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvNsAykCXGWa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grades"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEcpeY3_Xbi7",
        "colab_type": "text"
      },
      "source": [
        "Dataframes have inbuilt plotting functions (based on matplotlib), which allow for fast and convenient ways of visualizing the dataframe data.  The plot method:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPcgYt0OxixH",
        "colab_type": "text"
      },
      "source": [
        "#### Dataframe plotting methods\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKklxl0OX6zG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grades.plot()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gU_A8Q_NX-I9",
        "colab_type": "text"
      },
      "source": [
        "will produce a list of line plots, one for each column. On the x axis we have index values, and on the y axis column data. With this plot it's very easy to see that students had a very consistent performance across the three tests  (students 1 and 8 appear to have had special trouble with the 3rd test)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cectCod5Y54J",
        "colab_type": "text"
      },
      "source": [
        "Dataframes also have a convenient \"hist\" method for producing histograms:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X15Pmb_MXHGG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grades.hist();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygqGK8F6Z558",
        "colab_type": "text"
      },
      "source": [
        "The plot method has several sub-methods for specific plot styles. Let's suppose we wanto to plot 1st test grades against averages:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6-d0FYtXJnG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grades.plot.scatter(x='1st Test',y='Average')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsEZW-jPbLyk",
        "colab_type": "text"
      },
      "source": [
        "The \"plot\" method accepts a variety of parameters that can be passed onto the underlying matplotlib routines, like \"kind\", style\" and \"mfc\" (marker face color):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HQ9z90AZTZi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grades.plot(kind=\"line\", style='go-',mfc='black')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhIQTikBaNeD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5G4s26Zs9X_",
        "colab_type": "text"
      },
      "source": [
        "#### Exporting your dataframe to the Google Drive\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWhxqsxBtFMh",
        "colab_type": "text"
      },
      "source": [
        "Now that we haver prepared our \"grades\" dataframe with all the computations and columns, we may want to save it to a file, in a number of formats.\n",
        "\n",
        "Here we will see how to save to  a folder  in your google drive, in the Excel format."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPsqPq-buNea",
        "colab_type": "text"
      },
      "source": [
        "First, we need to *mount* our Google Drive on the VM file system. As explained in the \"reading and writing files\" notebook, we will use the google colab api with\n",
        "the authentication token mecanism:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQIEl04Nu2FM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BR42TayptEe8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drive.mount('/gdrive')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8y7xzFa3vODo",
        "colab_type": "text"
      },
      "source": [
        "Now that our Google drive is mounted at mountpoint \"/gdrive\", let's export  our data frame to an Excel \"xlsx\" file using the dataframe method \"`to_excel`\" :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-_dM-Dst2T3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grades.to_excel(\"/gdrive/My Drive/grades_colab.xlsx\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j12j5t4owFO0",
        "colab_type": "text"
      },
      "source": [
        "Let's check that the file is there:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ffa8fF0vveV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%ls /gdrive/My\\ Drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnOhoWL_wNdD",
        "colab_type": "text"
      },
      "source": [
        "Now go to your Google Drive and try to open the \"grades_colab.xlsx\" file with Google Spreadsheets. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yA1YSXEPv5Bm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}